{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Tt4pKVXp4qff",
    "outputId": "12316683-fa0a-4424-e7ec-3e58a611870a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel,BertTokenizer,FlaubertTokenizer, FlaubertModel,AutoTokenizer, BertForSequenceClassification , FlaubertForSequenceClassification\n",
    "from transformers.modeling_utils import SequenceSummary\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import sys\n",
    "import re\n",
    "from easy_nlp.models import BasicBertForClassification\n",
    "from easy_nlp.training import Train\n",
    "from easy_nlp.preprocessing import TextPreprocessing\n",
    "from easy_nlp.feature_extraction import MetaFeaturesExtraction\n",
    "from easy_nlp.data_visualisation import WordCloudMaker\n",
    "from transformers import  AutoModel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "i6mrcvEIjOBU"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "z1mzN2QD5Jv8",
    "outputId": "1740aa01-2243-4ffa-bc86-37c305663d68"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/data/aboumada/Data/3_Datasets/full_df_noFeatures_Preapred.csv\")\n",
    "#df=df[df.classe2 != 'Poubelle']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_preprocessing = TextPreprocessing(df,\"TEXT\")\n",
    "text_preprocessing.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['processed_text']=df['processed_text'].str.replace(r'pic.twitter.com(.*?)\\s(.*)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cloudMaker = WordCloudMaker.fit(df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run if Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train , df_test = train_test_split(df,random_state=1, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run if Out of event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#events_test= ['Bruno', 'Eleanor']\n",
    "#df_test = df[df.event.isin(events_test)]\n",
    "#df_train = df[~df.event.isin(events_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run if Out of Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "CPkgJxJddYhN"
   },
   "outputs": [],
   "source": [
    "#events_test= ['EffondrementMarseille']\n",
    "#df_train=df_en[['text_clean','CAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "2uM49TtI6LLN",
    "outputId": "2a4123e9-9923-4fd8-85b4-dde5c329ad10"
   },
   "outputs": [],
   "source": [
    "def get_sentences_labels(df,text_column='text_clean',label_column='CAT',cat_labels=None):\n",
    "    dic_cat_labels = cat_labels if cat_labels is not None else {x:value for x,value in enumerate(df[label_column].unique())}\n",
    "    dic_labels_to_cat = {value:x for x,value in dic_cat_labels.items() }\n",
    "    #df[text_column]= df[text_column].map(lambda text_clean : re.sub('[\"#$%&()*+,-./:;<=>@[\\]^_`{|}~\\n\\t’\\']', '', text_clean))\n",
    "    df2 = df[label_column].map(dic_labels_to_cat)\n",
    "    sentences = df[text_column].values\n",
    "    labels = df2.values.astype(int)\n",
    "    return sentences,labels,dic_cat_labels\n",
    "\n",
    "sentences_train,labels_train,dic_cat_labels=get_sentences_labels(df_train,text_column='processed_text',label_column='CAT')\n",
    "sentences_test,labels_test,dic_cat_labels=get_sentences_labels(df_test,text_column='processed_text',label_column='CAT',cat_labels=dic_cat_labels)\n",
    "\n",
    "print(dic_cat_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "fL7hMw6rehXc",
    "outputId": "ba2a219c-c7b8-4193-9c3d-f3ae72217731"
   },
   "source": [
    "## Run if you need to remove words used for data scrapping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "iHmNNf28ehXg",
    "outputId": "8b5ecdff-40d3-4e31-b460-05417e895c46"
   },
   "outputs": [],
   "source": [
    "'''crisis_names = ['irma','bruno','aude','harvey','eleanor','corse-fione','beryl−guadeloupe','corse','egon','susanna','ulrika','reunion−berguitta','marseille','effondrementmarseille','guadeloupe','corse','immeuble','martinique','saint martin','berguitta']\n",
    "crisis_scrap = ['marseille','bruno','crue', 'crues', 'aude', 'carcassonne', 'trèbes', 'trebes','corse', 'corsica', 'hautecorse', 'haute-corse','crue','béryl', 'beryl', 'guadeloupe', 'ondetropicale','réunion', 'reunion', 'lareunion', 'fakir', 'laréunion','réunion', 'reunion', 'lareunion',' berguitta',' laréunion','corse', 'fionn', 'corsica', 'ana','irma','ouraganIRMA', 'saintmartin', 'stmartin', 'saintbarthelemy', 'saintbarth', 'stbarth','harvey', 'martinique', 'guadeloupe','egon','ulrika', 'vendée','bretagne','susanna']\n",
    "crisis_scrap=crisis_scrap+crisis_names\n",
    "print(crisis_scrap)\n",
    "for i in range(len(sentences_train)):\n",
    "    big_regex = re.compile('|'.join(map(re.escape, crisis_scrap)))\n",
    "    sentences_train[i] = big_regex.sub(\" \", sentences_train[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "f72eddb948294b7bb00463d4ed6cc5af",
      "a0d22be9c5af47fba9826f45cb404d14",
      "d6a4103ed28c441aaece9f8f9f11c8b5",
      "60831d0d88144f8aa18798597bf1ac94",
      "2024e77c10704e18bbb473afa0f5a908",
      "94aca90ab4d843b3a2e9e067a2b92395",
      "16aebfb576bc463db97e5a222b9f264f",
      "0c2259b7d4ad4020ab30a1a849287ccf",
      "846e2eb2279a47a39ab28c47fc60ab54",
      "3744741d6d7c478ea51f4ed86cfcd437",
      "ce9418995bda46fc9efd0f24996e8167",
      "44175059856346149d08ed289d4179c3",
      "e9819ed7b8b74bc4ab9c31edb3a8caae",
      "0d362c6a6c9245f4815c934ccaf1d717",
      "51295ca06b7b457baeb45d11c6e77b09",
      "7b3b7019567541cf99bfb59c3780325c"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "fU3z3D5hNwnj",
    "outputId": "a21df7bc-f772-4ae0-a018-e7345d522bb1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from easy_nlp.feature_extraction import BertInput\n",
    "\n",
    "bert_input= BertInput(AutoTokenizer.from_pretrained('flaubert/flaubert_base_cased'))\n",
    "\n",
    "\n",
    "X_train = bert_input.fit_transform(sentences_train)\n",
    "X_test = bert_input.fit_transform(sentences_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "2qWr_SoAvjyD"
   },
   "outputs": [],
   "source": [
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels,train_masks,validation_masks = train_test_split(X_train[0], labels_train,X_train[1],random_state=1, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "#train_masks, validation_masks= train_test_split(,random_state=1, test_size=0.2)\n",
    "\n",
    "test_inputs = X_test[0]\n",
    "test_masks = X_test[1]\n",
    "test_labels = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "QLbLpNo1EyRX"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "YCqZsxQG8qkL",
    "outputId": "aa567bec-4ba5-4be6-ba15-8c11c20178cc"
   },
   "outputs": [],
   "source": [
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N44YvMDrowB7"
   },
   "outputs": [],
   "source": [
    "def get_label_callback(dataset,idx):\n",
    "    return dataset[idx][3].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "aDJeM2k1E02U"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
    "\n",
    "'''If you need to iblancedsampler uncomment this line if not use RandomSampler'''\n",
    "#train_sampler = ImbalancedDatasetSampler(train_data,callback_get_label=get_label_callback)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size,drop_last=True )\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs,validation_masks ,validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs,test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "dpLbwoAApnxJ"
   },
   "outputs": [],
   "source": [
    "print(len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained(\"flaubert/flaubert_base_cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = BasicBertForClassification(base_model,7)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "W3pKjPg9Ivds"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 1\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIABJxZ-19ii"
   },
   "source": [
    "### Run the tensoardBoard  tensorboard --logdir= \"Path to your folder\" to vizualize training \n",
    "__exemple__ :  tensorboard --logdir= runs/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qZAsjKnKI4Rx",
    "outputId": "b10dfd2d-35fb-47c6-9983-4b7a4cf615f1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from easy_nlp.models import FocalLoss2\n",
    "criterion = FocalLoss2(num_class= 7)\n",
    "train = Train()\n",
    "train.fit(model,train_dataloader,validation_dataloader,epochs,torch.device('cuda'),optimizer,scheduler,criterion,writer)\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.add_text('Train', 'This is an lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KzmtPO6OJbcG"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_dataloader)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Tracking variables \n",
    "predictions_cat,predictions_cat3,predictions_cat2 , true_labels_cat,true_labels_cat2  = [], [],[],[],[]\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(torch.device(\"cuda\")) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask,b_labels_cat = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model((b_input_ids,b_input_mask))\n",
    "        logits_cat = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits_cat = logits_cat.detach().cpu().numpy()\n",
    "    label_ids_cat = b_labels_cat.to('cpu').numpy()\n",
    "    predictions_cat.extend(logits_cat)\n",
    "    true_labels_cat.extend(label_ids_cat)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('    DONE.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat = np.argmax(predictions_cat, axis=1)\n",
    "true_labels_cat=[dic_cat_labels.get(x) for x in true_labels_cat]\n",
    "pred_flat_cat = [dic_cat_labels.get(x) for x in pred_flat_cat]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat,pred_flat_cat,digits=4)\n",
    "print(accuracy_score(pred_flat_cat,true_labels_cat))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "jF21fm-zehZd"
   },
   "outputs": [],
   "source": [
    "model.save(\"Crisis_Binary_flaubert_base.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Z3-BA_vfeha4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WnvSgbO0eha7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LuWeeaeEeha9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "DaB8pXo6ehbC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2u4UInmFehbG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y1_tjR61ehbK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1ObqrYFkehbN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AVpM54y3ehbQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B3UFEv2cehbT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Rr60uzFcehbW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flaubert_Multitask+learning+All.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch_tf_env",
   "language": "python",
   "name": "torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
