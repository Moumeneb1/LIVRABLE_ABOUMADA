{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Tt4pKVXp4qff",
    "outputId": "12316683-fa0a-4424-e7ec-3e58a611870a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,AutoTokenizer, FlaubertModel, BertForSequenceClassification , FlaubertForSequenceClassification\n",
    "from transformers.modeling_utils import SequenceSummary\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import sys\n",
    "import re\n",
    "from easy_nlp.models import ThreeTaskLearning\n",
    "from easy_nlp.training import Train\n",
    "from easy_nlp.preprocessing import TextPreprocessing\n",
    "from easy_nlp.feature_extraction import MetaFeaturesExtraction\n",
    "from easy_nlp.data_visualisation import WordCloudMaker\n",
    "from transformers import  AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "z1mzN2QD5Jv8",
    "outputId": "1740aa01-2243-4ffa-bc86-37c305663d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12826"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/data/aboumada/Data/3_Datasets/full_df_noFeatures2.csv\")\n",
    "#df_en = pd.read_csv('/data/aboumada/Data/3_Datasets/anonym_final_en_1.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from easy_nlp.preprocessing import TextPreprocessing\n",
    "tp=TextPreprocessing(df,'TEXT')\n",
    "tp.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PNP1f-OrehXK",
    "outputId": "24902c98-68b5-492f-9ee0-8509eddc17b6"
   },
   "source": [
    "## Run if Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train , df_test = train_test_split(df,random_state=1, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Run if Out of event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#events_test= ['Bruno', 'Eleanor']\n",
    "#df_test = df[df.event.isin(events_test)]\n",
    "#df_train = df[~df.event.isin(events_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run if Out of Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#events_test= ['EffondrementMarseille']\n",
    "#df_train=df_en[['text_clean','CAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lmxzSGxF2y8u",
    "outputId": "320825e1-75c6-41fc-cb3f-df9968588952"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9sctUMZj3y8Z",
    "outputId": "3e78bdad-f240-415a-d115-e2e910a0f030"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "2uM49TtI6LLN",
    "outputId": "2a4123e9-9923-4fd8-85b4-dde5c329ad10"
   },
   "outputs": [],
   "source": [
    "def get_sentences_labels(df,text_column='text_clean',label_column='CAT'):    \n",
    "    dic_labels_to_cat = {value:x for x,value in enumerate(df[label_column].unique())}\n",
    "    dic_cat_labels = {x:value for x,value in enumerate(df[label_column].unique())}\n",
    "    df['text_clean']= df['text_clean'].map(lambda text_clean : re.sub('[\"#$%&()*+,-./:;<=>@[\\]^_`{|}~\\n\\t’\\']', '', text_clean))\n",
    "    df2 = df[label_column].map(dic_labels_to_cat)\n",
    "    sentences = df[text_column].values\n",
    "    labels = df2.values.astype(int)\n",
    "    return sentences,labels,dic_cat_labels\n",
    "\n",
    "def custom_sentences_labels(df,dic_cat,dic_cat3,dic_cat2,text_column='text_clean',label_column='CAT'):\n",
    "    dic_cat_labe = dic_cat\n",
    "    dic_cat_labe2 = dic_cat2\n",
    "    dic_cat_labe3 = dic_cat3\n",
    "    #df['text_clean']= df['text_clean'].map(lambda text_clean : re.sub('[\"#$%&()*+,-./:;<=>@[\\]^_`{|}~\\n\\t’\\']', '', text_clean))\n",
    "    dic_labels_to_cat = {v: k for k, v in dic_cat_labe.items()}\n",
    "    dic_labels_to_cat2 = {v: k for k, v in dic_cat_labe2.items()}\n",
    "    dic_labels_to_cat3 = {v: k for k, v in dic_cat_labe3.items()}\n",
    "    sentences = df[text_column].values\n",
    "    df_cat = df['CAT'].map(dic_labels_to_cat)\n",
    "    labels_CAT = df_cat.values.astype(int)\n",
    "    df_cat2 = df['CAT2'].map(dic_labels_to_cat2)\n",
    "    labels_CAT2 = df_cat2.values.astype(int)\n",
    "    df_cat3 = df['CAT3'].map(dic_labels_to_cat3)\n",
    "    labels_CAT3 = df_cat3.values.astype(int)\n",
    "\n",
    "    return sentences,(labels_CAT,labels_CAT3,labels_CAT2),dic_cat_labe\n",
    "\n",
    "dic_cat_labels_CAT = {0: 'Soutiens', 1: 'Message-NonUtilisable', 2: 'Degats-Humains', 3: 'Degats-Materiels', 4: 'Avertissement-conseil', 5: 'AutresMessages',6: 'Critiques'}\n",
    "dic_cat_labels_CAT3 = {0: 'Message-InfoUrgent', 1: 'Message-NonUtilisable', 2: 'Message-InfoNonUrgent'}\n",
    "dic_cat_labels_CAT2 = {0: 'Message-Utilisable', 1: 'Message-NonUtilisable'}\n",
    "\n",
    "#sentences_train,labels_train,dic_cat_labels=get_sentences_labels(df_train,text_column='text_clean',label_column='CAT')\n",
    "sentences_train,labels_train,_=custom_sentences_labels(df_train,dic_cat_labels_CAT,dic_cat_labels_CAT3,dic_cat_labels_CAT2,text_column='processed_text',label_column='CAT')\n",
    "sentences_test,test_labels,_=custom_sentences_labels(df_test,dic_cat_labels_CAT,dic_cat_labels_CAT3,dic_cat_labels_CAT2,text_column='processed_text',label_column='CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "f72eddb948294b7bb00463d4ed6cc5af",
      "a0d22be9c5af47fba9826f45cb404d14",
      "d6a4103ed28c441aaece9f8f9f11c8b5",
      "60831d0d88144f8aa18798597bf1ac94",
      "2024e77c10704e18bbb473afa0f5a908",
      "94aca90ab4d843b3a2e9e067a2b92395",
      "16aebfb576bc463db97e5a222b9f264f",
      "0c2259b7d4ad4020ab30a1a849287ccf",
      "846e2eb2279a47a39ab28c47fc60ab54",
      "3744741d6d7c478ea51f4ed86cfcd437",
      "ce9418995bda46fc9efd0f24996e8167",
      "44175059856346149d08ed289d4179c3",
      "e9819ed7b8b74bc4ab9c31edb3a8caae",
      "0d362c6a6c9245f4815c934ccaf1d717",
      "51295ca06b7b457baeb45d11c6e77b09",
      "7b3b7019567541cf99bfb59c3780325c"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "fU3z3D5hNwnj",
    "outputId": "a21df7bc-f772-4ae0-a018-e7345d522bb1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from easy_nlp.feature_extraction import BertInput\n",
    "\n",
    "bert_input= BertInput(AutoTokenizer.from_pretrained('bert-base-multilingual-cased'))\n",
    "\n",
    "\n",
    "X_train = bert_input.fit_transform(sentences_train)\n",
    "X_test = bert_input.fit_transform(sentences_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "2qWr_SoAvjyD"
   },
   "outputs": [],
   "source": [
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels_cat, validation_labels_cat,train_labels_cat3, validation_labels_cat3,train_labels_cat2, validation_labels_cat2 = train_test_split(X_train[0], labels_train[0], labels_train[1], labels_train[2],\n",
    "                                                            random_state=1, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks= train_test_split(X_train[1],\n",
    "                                             random_state=1, test_size=0.2)\n",
    "\n",
    "test_inputs = X_test[0]\n",
    "test_masks = X_test[1]\n",
    "test_labels_cat = test_labels[0]\n",
    "test_labels_cat3 = test_labels[1]\n",
    "test_labels_cat2 = test_labels[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "e9EtZELWvQNq",
    "outputId": "5144d70e-584b-4e56-c27f-9dcd0945ab49"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5MHONo0BEwRR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "QLbLpNo1EyRX"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels_cat = torch.tensor(train_labels_cat)\n",
    "validation_labels_cat = torch.tensor(validation_labels_cat)\n",
    "test_labels_cat = torch.tensor(test_labels_cat)\n",
    "\n",
    "train_labels_cat3 = torch.tensor(train_labels_cat3)\n",
    "validation_labels_cat3 = torch.tensor(validation_labels_cat3)\n",
    "test_labels_cat3 = torch.tensor(test_labels_cat3)\n",
    "\n",
    "train_labels_cat2 = torch.tensor(train_labels_cat2)\n",
    "validation_labels_cat2 = torch.tensor(validation_labels_cat2)\n",
    "test_labels_cat2 = torch.tensor(test_labels_cat2)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "YCqZsxQG8qkL",
    "outputId": "aa567bec-4ba5-4be6-ba15-8c11c20178cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N44YvMDrowB7"
   },
   "outputs": [],
   "source": [
    "def get_label_callback(dataset,idx):\n",
    "    return dataset[idx][3].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EplrI9njoxJl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "iIawUkP_popj",
    "outputId": "ef5231b9-97df-4c4e-e6e3-7242d4675162"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "aDJeM2k1E02U"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels_cat,train_labels_cat3,train_labels_cat2)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "#train_sampler = ImbalancedDatasetSampler(train_data,callback_get_label=get_label_callback)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs,validation_masks ,validation_labels_cat,validation_labels_cat3,validation_labels_cat2)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs,test_masks, test_labels_cat,test_labels_cat3,test_labels_cat2)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dpLbwoAApnxJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ql6VZYido-w_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4f9cae1d99f3443fb98b00a4f7e682cf",
      "ff14b9e555c54d7c89c1dbbff543b47b",
      "77980552d8a344929721990a95e75f95",
      "06a769832535409e90bebadf4385bf56",
      "d73a2248948b4a8ba64d0c61d3c4a0e7",
      "ef456ebc1a3f459d8db57ffa12f509bd",
      "f6aadf099bc54f279d31aacca1e7ed89",
      "065edcd156034674802afe441b506472",
      "8e96be71b679486e89215ca965df9e9b",
      "273dc786cb2c49f29b2acb292eba3b9b",
      "fe09e9ce448e47f5baf8074e72c8f99f",
      "795050feb4c9465c80729c5184dbac43",
      "652b303e2fb648069359c59e57ff5367",
      "8cb852ff447a4dd5b106bf78f46fa11f",
      "bd9b36bf1b7040d59206b02525d8daaf",
      "c8615680e0404a47b76b3e9cf2c6b395"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Q-w7gOSsE3gg",
    "outputId": "36f4257e-2451-4b4a-bee9-81631d68e23f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeTaskLearning(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_cat): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (linear_cat3): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (linear_cat2): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (activation): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ThreeTaskLearning(model=AutoModel.from_pretrained('bert-base-multilingual-cased'),\n",
    "        dropout_rate = 0.1, \n",
    "        device = torch.device(\"cuda\"),\n",
    "        )\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4OzL-JucAhxR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iA51FWSoS5na"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "W3pKjPg9Ivds"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 3e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 1\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yhDsewdSehZD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIABJxZ-19ii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qZAsjKnKI4Rx",
    "outputId": "b10dfd2d-35fb-47c6-9983-4b7a4cf615f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    40  of    513.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    513.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    513.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    513.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    513.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    513.    Elapsed: 0:00:58.\n",
      "  Batch   280  of    513.    Elapsed: 0:01:07.\n",
      "  Batch   320  of    513.    Elapsed: 0:01:16.\n",
      "  Batch   360  of    513.    Elapsed: 0:01:26.\n",
      "  Batch   400  of    513.    Elapsed: 0:01:35.\n",
      "  Batch   440  of    513.    Elapsed: 0:01:44.\n",
      "  Batch   480  of    513.    Elapsed: 0:01:53.\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epcoh took: 0:02:01\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "save currently the best model to [tmp]\n",
      "save model parameters to [tmp]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.85\n",
      "  F1: 0.80\n",
      "  Recall: 0.82\n",
      "  Precision: 0.81\n",
      "  Validation took: 0:00:10\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = Train()\n",
    "train.fit_ThreeTask(model,train_dataloader,validation_dataloader,epochs,torch.device('cuda'),optimizer,scheduler)\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KzmtPO6OJbcG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 161 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_dataloader)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Tracking variables \n",
    "predictions_cat,predictions_cat3,predictions_cat2 , true_labels_cat,true_labels_cat3,true_labels_cat2  = [], [],[],[],[],[]\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(torch.device(\"cuda\")) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask,b_labels_cat,b_labels_cat3,b_labels_cat2 = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model((b_input_ids,b_input_mask))\n",
    "        logits_cat = outputs[0]\n",
    "        logits_cat3 = outputs[1]\n",
    "        logits_cat2 = outputs[2]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits_cat = logits_cat.detach().cpu().numpy()\n",
    "    label_ids_cat = b_labels_cat.to('cpu').numpy()\n",
    "    predictions_cat.extend(logits_cat)\n",
    "    true_labels_cat.extend(label_ids_cat)\n",
    "    \n",
    "    logits_cat3 = logits_cat3.detach().cpu().numpy()\n",
    "    label_ids_cat3 = b_labels_cat3.to('cpu').numpy()\n",
    "    predictions_cat3.extend(logits_cat3)\n",
    "    true_labels_cat3.extend(label_ids_cat3)\n",
    "    \n",
    "    \n",
    "    logits_cat2 = logits_cat2.detach().cpu().numpy()\n",
    "    label_ids_cat2 = b_labels_cat2.to('cpu').numpy()\n",
    "    predictions_cat2.extend(logits_cat2)\n",
    "    true_labels_cat2.extend(label_ids_cat2)\n",
    "\n",
    "\n",
    "print('    DONE.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "n44qF6NPKHcv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8191738113795791\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       AutresMessages     0.5000    0.2079    0.2937       178\n",
      "Avertissement-conseil     0.7326    0.7104    0.7214       297\n",
      "            Critiques     0.0000    0.0000    0.0000        28\n",
      "       Degats-Humains     0.7027    0.5306    0.6047        49\n",
      "     Degats-Materiels     0.6923    0.4839    0.5696        93\n",
      "Message-NonUtilisable     0.8509    0.9464    0.8961      1827\n",
      "             Soutiens     0.7714    0.5745    0.6585        94\n",
      "\n",
      "             accuracy                         0.8192      2566\n",
      "            macro avg     0.6071    0.4934    0.5348      2566\n",
      "         weighted avg     0.7921    0.8192    0.7982      2566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat = np.argmax(predictions_cat, axis=1)\n",
    "true_labels_cat=[dic_cat_labels_CAT.get(x) for x in true_labels_cat]\n",
    "pred_flat_cat = [dic_cat_labels_CAT.get(x) for x in pred_flat_cat]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat,pred_flat_cat,digits=4)\n",
    "print(accuracy_score(pred_flat_cat,true_labels_cat))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "jF21fm-zehZd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8312548713951676\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Message-InfoNonUrgent     0.6528    0.4200    0.5112       300\n",
      "   Message-InfoUrgent     0.7349    0.7198    0.7273       439\n",
      "Message-NonUtilisable     0.8703    0.9256    0.8971      1827\n",
      "\n",
      "             accuracy                         0.8313      2566\n",
      "            macro avg     0.7527    0.6885    0.7118      2566\n",
      "         weighted avg     0.8217    0.8313    0.8229      2566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat3 = np.argmax(predictions_cat3, axis=1)\n",
    "true_labels_cat3 =[dic_cat_labels_CAT3.get(x) for x in true_labels_cat3]\n",
    "pred_flat_cat3 = [dic_cat_labels_CAT3.get(x) for x in pred_flat_cat3]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat3,pred_flat_cat3,digits=4)\n",
    "print(accuracy_score(pred_flat_cat3,true_labels_cat3))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "HEIPOlO8ehZh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495713172252534\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Message-NonUtilisable     0.8863    0.9048    0.8954      1827\n",
      "   Message-Utilisable     0.7518    0.7131    0.7319       739\n",
      "\n",
      "             accuracy                         0.8496      2566\n",
      "            macro avg     0.8191    0.8089    0.8137      2566\n",
      "         weighted avg     0.8476    0.8496    0.8484      2566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat2 = np.argmax(predictions_cat2, axis=1)\n",
    "true_labels_cat2 =[dic_cat_labels_CAT2.get(x) for x in true_labels_cat2]\n",
    "pred_flat_cat2 = [dic_cat_labels_CAT2.get(x) for x in pred_flat_cat2]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat2,pred_flat_cat2,digits=4)\n",
    "print(accuracy_score(pred_flat_cat2,true_labels_cat2))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "MxFV4TGAehZl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save model parameters to [model.pth]\n"
     ]
    }
   ],
   "source": [
    "model.save('model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flaubert_Multitask+learning+All.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch_tf_env",
   "language": "python",
   "name": "torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
