{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Tt4pKVXp4qff",
    "outputId": "12316683-fa0a-4424-e7ec-3e58a611870a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,AutoTokenizer, FlaubertModel, BertForSequenceClassification , FlaubertForSequenceClassification\n",
    "from transformers.modeling_utils import SequenceSummary\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import sys\n",
    "import re\n",
    "from easy_nlp.models import ThreeTaskLearning\n",
    "from easy_nlp.training import Train\n",
    "from easy_nlp.preprocessing import TextPreprocessing\n",
    "from easy_nlp.feature_extraction import MetaFeaturesExtraction\n",
    "from easy_nlp.data_visualisation import WordCloudMaker\n",
    "from transformers import  AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "z1mzN2QD5Jv8",
    "outputId": "1740aa01-2243-4ffa-bc86-37c305663d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12826"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/data/aboumada/Data/3_Datasets/full_df_noFeatures2.csv\")\n",
    "#df_en = pd.read_csv('/data/aboumada/Data/3_Datasets/anonym_final_en_1.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from easy_nlp.preprocessing import TextPreprocessing\n",
    "tp=TextPreprocessing(df,'TEXT')\n",
    "tp.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PNP1f-OrehXK",
    "outputId": "24902c98-68b5-492f-9ee0-8509eddc17b6"
   },
   "source": [
    "## Run if Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train , df_test = train_test_split(df,random_state=1, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Run if Out of event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#events_test= ['Bruno', 'Eleanor']\n",
    "#df_test = df[df.event.isin(events_test)]\n",
    "#df_train = df[~df.event.isin(events_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run if Out of Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#events_test= ['EffondrementMarseille']\n",
    "#df_train=df_en[['text_clean','CAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lmxzSGxF2y8u",
    "outputId": "320825e1-75c6-41fc-cb3f-df9968588952"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9sctUMZj3y8Z",
    "outputId": "3e78bdad-f240-415a-d115-e2e910a0f030"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "2uM49TtI6LLN",
    "outputId": "2a4123e9-9923-4fd8-85b4-dde5c329ad10"
   },
   "outputs": [],
   "source": [
    "def get_sentences_labels(df,text_column='text_clean',label_column='CAT'):    \n",
    "    dic_labels_to_cat = {value:x for x,value in enumerate(df[label_column].unique())}\n",
    "    dic_cat_labels = {x:value for x,value in enumerate(df[label_column].unique())}\n",
    "    df['text_clean']= df['text_clean'].map(lambda text_clean : re.sub('[\"#$%&()*+,-./:;<=>@[\\]^_`{|}~\\n\\t’\\']', '', text_clean))\n",
    "    df2 = df[label_column].map(dic_labels_to_cat)\n",
    "    sentences = df[text_column].values\n",
    "    labels = df2.values.astype(int)\n",
    "    return sentences,labels,dic_cat_labels\n",
    "\n",
    "def custom_sentences_labels(df,dic_cat,dic_cat3,dic_cat2,text_column='text_clean',label_column='CAT'):\n",
    "    dic_cat_labe = dic_cat\n",
    "    dic_cat_labe2 = dic_cat2\n",
    "    dic_cat_labe3 = dic_cat3\n",
    "    #df['text_clean']= df['text_clean'].map(lambda text_clean : re.sub('[\"#$%&()*+,-./:;<=>@[\\]^_`{|}~\\n\\t’\\']', '', text_clean))\n",
    "    dic_labels_to_cat = {v: k for k, v in dic_cat_labe.items()}\n",
    "    dic_labels_to_cat2 = {v: k for k, v in dic_cat_labe2.items()}\n",
    "    dic_labels_to_cat3 = {v: k for k, v in dic_cat_labe3.items()}\n",
    "    sentences = df[text_column].values\n",
    "    df_cat = df['CAT'].map(dic_labels_to_cat)\n",
    "    labels_CAT = df_cat.values.astype(int)\n",
    "    df_cat2 = df['CAT2'].map(dic_labels_to_cat2)\n",
    "    labels_CAT2 = df_cat2.values.astype(int)\n",
    "    df_cat3 = df['CAT3'].map(dic_labels_to_cat3)\n",
    "    labels_CAT3 = df_cat3.values.astype(int)\n",
    "\n",
    "    return sentences,(labels_CAT,labels_CAT3,labels_CAT2),dic_cat_labe\n",
    "\n",
    "dic_cat_labels_CAT = {0: 'Soutiens', 1: 'Message-NonUtilisable', 2: 'Degats-Humains', 3: 'Degats-Materiels', 4: 'Avertissement-conseil', 5: 'AutresMessages',6: 'Critiques'}\n",
    "dic_cat_labels_CAT3 = {0: 'Message-InfoUrgent', 1: 'Message-NonUtilisable', 2: 'Message-InfoNonUrgent'}\n",
    "dic_cat_labels_CAT2 = {0: 'Message-Utilisable', 1: 'Message-NonUtilisable'}\n",
    "\n",
    "#sentences_train,labels_train,dic_cat_labels=get_sentences_labels(df_train,text_column='text_clean',label_column='CAT')\n",
    "sentences_train,labels_train,_=custom_sentences_labels(df_train,dic_cat_labels_CAT,dic_cat_labels_CAT3,dic_cat_labels_CAT2,text_column='processed_text',label_column='CAT')\n",
    "sentences_test,test_labels,_=custom_sentences_labels(df_test,dic_cat_labels_CAT,dic_cat_labels_CAT3,dic_cat_labels_CAT2,text_column='processed_text',label_column='CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "f72eddb948294b7bb00463d4ed6cc5af",
      "a0d22be9c5af47fba9826f45cb404d14",
      "d6a4103ed28c441aaece9f8f9f11c8b5",
      "60831d0d88144f8aa18798597bf1ac94",
      "2024e77c10704e18bbb473afa0f5a908",
      "94aca90ab4d843b3a2e9e067a2b92395",
      "16aebfb576bc463db97e5a222b9f264f",
      "0c2259b7d4ad4020ab30a1a849287ccf",
      "846e2eb2279a47a39ab28c47fc60ab54",
      "3744741d6d7c478ea51f4ed86cfcd437",
      "ce9418995bda46fc9efd0f24996e8167",
      "44175059856346149d08ed289d4179c3",
      "e9819ed7b8b74bc4ab9c31edb3a8caae",
      "0d362c6a6c9245f4815c934ccaf1d717",
      "51295ca06b7b457baeb45d11c6e77b09",
      "7b3b7019567541cf99bfb59c3780325c"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "fU3z3D5hNwnj",
    "outputId": "a21df7bc-f772-4ae0-a018-e7345d522bb1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from easy_nlp.feature_extraction import BertInput\n",
    "\n",
    "bert_input= BertInput(AutoTokenizer.from_pretrained('flaubert/flaubert_base_cased'))\n",
    "\n",
    "\n",
    "X_train = bert_input.fit_transform(sentences_train)\n",
    "X_test = bert_input.fit_transform(sentences_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "2qWr_SoAvjyD"
   },
   "outputs": [],
   "source": [
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels_cat, validation_labels_cat,train_labels_cat3, validation_labels_cat3,train_labels_cat2, validation_labels_cat2 = train_test_split(X_train[0], labels_train[0], labels_train[1], labels_train[2],\n",
    "                                                            random_state=1, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks= train_test_split(X_train[1],\n",
    "                                             random_state=1, test_size=0.2)\n",
    "\n",
    "test_inputs = X_test[0]\n",
    "test_masks = X_test[1]\n",
    "test_labels_cat = test_labels[0]\n",
    "test_labels_cat3 = test_labels[1]\n",
    "test_labels_cat2 = test_labels[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "e9EtZELWvQNq",
    "outputId": "5144d70e-584b-4e56-c27f-9dcd0945ab49"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5MHONo0BEwRR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "QLbLpNo1EyRX"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels_cat = torch.tensor(train_labels_cat)\n",
    "validation_labels_cat = torch.tensor(validation_labels_cat)\n",
    "test_labels_cat = torch.tensor(test_labels_cat)\n",
    "\n",
    "train_labels_cat3 = torch.tensor(train_labels_cat3)\n",
    "validation_labels_cat3 = torch.tensor(validation_labels_cat3)\n",
    "test_labels_cat3 = torch.tensor(test_labels_cat3)\n",
    "\n",
    "train_labels_cat2 = torch.tensor(train_labels_cat2)\n",
    "validation_labels_cat2 = torch.tensor(validation_labels_cat2)\n",
    "test_labels_cat2 = torch.tensor(test_labels_cat2)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "YCqZsxQG8qkL",
    "outputId": "aa567bec-4ba5-4be6-ba15-8c11c20178cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N44YvMDrowB7"
   },
   "outputs": [],
   "source": [
    "def get_label_callback(dataset,idx):\n",
    "    return dataset[idx][3].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EplrI9njoxJl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "iIawUkP_popj",
    "outputId": "ef5231b9-97df-4c4e-e6e3-7242d4675162"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "aDJeM2k1E02U"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels_cat,train_labels_cat3,train_labels_cat2)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "#train_sampler = ImbalancedDatasetSampler(train_data,callback_get_label=get_label_callback)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs,validation_masks ,validation_labels_cat,validation_labels_cat3,validation_labels_cat2)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs,test_masks, test_labels_cat,test_labels_cat3,test_labels_cat2)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dpLbwoAApnxJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ql6VZYido-w_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4f9cae1d99f3443fb98b00a4f7e682cf",
      "ff14b9e555c54d7c89c1dbbff543b47b",
      "77980552d8a344929721990a95e75f95",
      "06a769832535409e90bebadf4385bf56",
      "d73a2248948b4a8ba64d0c61d3c4a0e7",
      "ef456ebc1a3f459d8db57ffa12f509bd",
      "f6aadf099bc54f279d31aacca1e7ed89",
      "065edcd156034674802afe441b506472",
      "8e96be71b679486e89215ca965df9e9b",
      "273dc786cb2c49f29b2acb292eba3b9b",
      "fe09e9ce448e47f5baf8074e72c8f99f",
      "795050feb4c9465c80729c5184dbac43",
      "652b303e2fb648069359c59e57ff5367",
      "8cb852ff447a4dd5b106bf78f46fa11f",
      "bd9b36bf1b7040d59206b02525d8daaf",
      "c8615680e0404a47b76b3e9cf2c6b395"
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Q-w7gOSsE3gg",
    "outputId": "36f4257e-2451-4b4a-bee9-81631d68e23f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeTaskLearning(\n",
       "  (bert): FlaubertModel(\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (embeddings): Embedding(68729, 768, padding_idx=2)\n",
       "    (layer_norm_emb): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (attentions): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (4): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (5): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (6): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (7): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (8): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (9): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (10): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (11): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm1): ModuleList(\n",
       "      (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (ffns): ModuleList(\n",
       "      (0): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (4): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (5): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (6): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (7): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (8): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (9): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (10): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (11): TransformerFFN(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm2): ModuleList(\n",
       "      (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_cat): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (linear_cat3): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (linear_cat2): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (activation): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ThreeTaskLearning(model=AutoModel.from_pretrained('flaubert-base-cased'),\n",
    "        dropout_rate = 0.1, \n",
    "        device = torch.device(\"cuda\"),\n",
    "        )\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4OzL-JucAhxR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iA51FWSoS5na"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "W3pKjPg9Ivds"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 3e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 1\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yhDsewdSehZD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIABJxZ-19ii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qZAsjKnKI4Rx",
    "outputId": "b10dfd2d-35fb-47c6-9983-4b7a4cf615f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    40  of    513.    Elapsed: 0:00:08.\n",
      "  Batch    80  of    513.    Elapsed: 0:00:16.\n",
      "  Batch   120  of    513.    Elapsed: 0:00:24.\n",
      "  Batch   160  of    513.    Elapsed: 0:00:32.\n",
      "  Batch   200  of    513.    Elapsed: 0:00:40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-42-ee4e1cde89b4>\", line 3, in <module>\n",
      "    train.fit_ThreeTask(model,train_dataloader,validation_dataloader,epochs,torch.device('cuda'),optimizer,scheduler)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/easy_nlp/training/train.py\", line 588, in fit_ThreeTask\n",
      "    optimizer.step()\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 66, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/transformers/optimization.py\", line 157, in step\n",
      "    denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/aboumada/anaconda3/envs/torch_tf/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = Train()\n",
    "train.fit_ThreeTask(model,train_dataloader,validation_dataloader,epochs,torch.device('cuda'),optimizer,scheduler)\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "KzmtPO6OJbcG"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_dataloader)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Tracking variables \n",
    "predictions_cat,predictions_cat3,predictions_cat2 , true_labels_cat,true_labels_cat3,true_labels_cat2  = [], [],[],[],[],[]\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(torch.device(\"cuda\")) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask,b_labels_cat,b_labels_cat3,b_labels_cat2 = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model((b_input_ids,b_input_mask))\n",
    "        logits_cat = outputs[0]\n",
    "        logits_cat3 = outputs[1]\n",
    "        logits_cat2 = outputs[2]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits_cat = logits_cat.detach().cpu().numpy()\n",
    "    label_ids_cat = b_labels_cat.to('cpu').numpy()\n",
    "    predictions_cat.extend(logits_cat)\n",
    "    true_labels_cat.extend(label_ids_cat)\n",
    "    \n",
    "    logits_cat3 = logits_cat3.detach().cpu().numpy()\n",
    "    label_ids_cat3 = b_labels_cat3.to('cpu').numpy()\n",
    "    predictions_cat3.extend(logits_cat3)\n",
    "    true_labels_cat3.extend(label_ids_cat3)\n",
    "    \n",
    "    \n",
    "    logits_cat2 = logits_cat2.detach().cpu().numpy()\n",
    "    label_ids_cat2 = b_labels_cat2.to('cpu').numpy()\n",
    "    predictions_cat2.extend(logits_cat2)\n",
    "    true_labels_cat2.extend(label_ids_cat2)\n",
    "\n",
    "\n",
    "print('    DONE.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "n44qF6NPKHcv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat = np.argmax(predictions_cat, axis=1)\n",
    "true_labels_cat=[dic_cat_labels_CAT.get(x) for x in true_labels_cat]\n",
    "pred_flat_cat = [dic_cat_labels_CAT.get(x) for x in pred_flat_cat]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat,pred_flat_cat,digits=4)\n",
    "print(accuracy_score(pred_flat_cat,true_labels_cat))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "jF21fm-zehZd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat3 = np.argmax(predictions_cat3, axis=1)\n",
    "true_labels_cat3 =[dic_cat_labels_CAT3.get(x) for x in true_labels_cat3]\n",
    "pred_flat_cat3 = [dic_cat_labels_CAT3.get(x) for x in pred_flat_cat3]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat3,pred_flat_cat3,digits=4)\n",
    "print(accuracy_score(pred_flat_cat3,true_labels_cat3))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "HEIPOlO8ehZh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_flat_cat2 = np.argmax(predictions_cat2, axis=1)\n",
    "true_labels_cat2 =[dic_cat_labels_CAT2.get(x) for x in true_labels_cat2]\n",
    "pred_flat_cat2 = [dic_cat_labels_CAT2.get(x) for x in pred_flat_cat2]\n",
    "\n",
    "\n",
    "cr= classification_report(true_labels_cat2,pred_flat_cat2,digits=4)\n",
    "print(accuracy_score(pred_flat_cat2,true_labels_cat2))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "MxFV4TGAehZl"
   },
   "outputs": [],
   "source": [
    "model.save('model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flaubert_Multitask+learning+All.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch_tf_env",
   "language": "python",
   "name": "torch_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
